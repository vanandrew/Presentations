{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "$(document).ready(function(){\n",
       "\n",
       "    Reveal.configure({\n",
       "        transition: 'convex' // none/fade/slide/convex/concave/zoom\n",
       "    })\n",
       "});    \n",
       "</script>\n",
       "<a href=\"javascript:code_toggle()\"><button>Toggle Code</button></a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use NBviewer for better rendering ----------------------------->S\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<a href=\"javascript:code_toggle()\"><button>Toggle Code</button></a>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Generative Adversarial Nets</center></h1>\n",
    "<br>\n",
    "<p><center>Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio</center></p>\n",
    "<h6><center>Université de Montréal</center></h6>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<p style=\"font-size: 10px;\">CMI Lab Journal Club, 02/18/2019, Andrew Van</p>\n",
    "<script type=\"text/javascript\">\n",
    "$(window).load(function(){\n",
    "    Reveal.configure({\n",
    "        transition: 'fade' // none/fade/slide/convex/concave/zoom\n",
    "    })\n",
    "});    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>The motivation for GANs</center></h3>\n",
    "\n",
    "- They can make really convincing fake images!\n",
    "\n",
    "<div style=\"width:fit-content;display:block;margin-right:auto;margin-left:auto;\">\n",
    "<img src=\"images/stylegan-teaser.png\" width=100% height=auto>\n",
    "</div>\n",
    "<p><center>These are not real people! <a href=\"https://arxiv.org/abs/1812.04948\" target=\"_blank\">StyleGAN</a></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>The motivation for GANs</center></h3>\n",
    "\n",
    "<div style=\"width:fit-content;display:block;margin-right:auto;margin-left:auto;\">\n",
    "<img src=\"images/superresolution.png\" width=100% height=auto>\n",
    "</div>\n",
    "<p><center><a href=\"https://arxiv.org/abs/1609.04802\" target=\"_blank\">Super-Resolution</a></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>The motivation for GANs</center></h3>\n",
    "\n",
    "<div style=\"width:fit-content;display:block;margin-right:auto;margin-left:auto;\">\n",
    "<img src=\"images/highresimgsynth.gif\" width=100% height=auto>\n",
    "</div>\n",
    "<p><center><a href=\"https://arxiv.org/abs/1711.11585\" target=\"_blank\">High-resolution image synthesis</a></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>The motivation for GANs</center></h3>\n",
    "\n",
    "<div style=\"width:fit-content;display:block;margin-right:auto;margin-left:auto;\">\n",
    "<img src=\"images/imageinpainting.png\" width=100% height=auto>\n",
    "</div>\n",
    "<p><center><a href=\"https://arxiv.org/abs/1604.07379\" target=\"_blank\">Image Inpainting</a></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>The motivation for GANs</center></h3>\n",
    "\n",
    "<div style=\"width:fit-content;display:block;margin-right:auto;margin-left:auto;\">\n",
    "<img style=\"display:block;margin:auto;\" src=\"images/tumor.png\" width=75% height=auto>\n",
    "</div>\n",
    "<div style=\"width:fit-content;display:block;margin-right:auto;margin-left:auto;\">\n",
    "<img style=\"display:block;margin:auto;\" src=\"images/tumor2.png\" width=75% height=auto>\n",
    "</div>\n",
    "<p><center><a href=\"https://arxiv.org/abs/1703.05921\" target=\"_blank\">Anomaly Detection (Tumor Detection)</a></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Overview</center></h3>\n",
    "\n",
    "- Generative Modeling\n",
    "- Adversarial Training\n",
    "- Theoretical guarantees of optimality/convergence\n",
    "- Results/Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>What is generative modeling?</center></h3>\n",
    "\n",
    "- Most successes in deep learning so far have been discriminative models\n",
    "    - Mapping high-dimensional data to a class label\n",
    "    - e.g. Given an image, is it a cat/dog?\n",
    "- Generative models answer a somewhat opposite question\n",
    "    - Given a sample drawn from a distribution, we want to learn an estimate of that distribution\n",
    "    - e.g. Given a set of cats/dogs, learn the images that generate each class.\n",
    "    \n",
    "<div style=\"width:fit-content;display:block;margin-right:auto;margin-left:auto;\">\n",
    "<img src=\"images/density_estimation.png\" width=100% height=auto>\n",
    "</div>\n",
    "<p><center>Generative Modeling: Estimating a distribution from a sample</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Generative modeling from the framework of Maximum Likelihood</center></h3>\n",
    "\n",
    "- We want to estimate a distribution $p_{data}$, from the empirical distribution $\\hat{p}_{data}$ (our training data/sample).\n",
    "- Define a model, $p_{model}({\\bf x}; \\theta)$ parameterized by $\\theta$.\n",
    "- We want $p_{model}$ to estimate $p_{data}$, using samples, ${\\bf x}^{(i)}$, drawn from $\\hat{p}_{data}$\n",
    "- We want to solve:\n",
    "$$\\theta^{*} = \\underset{\\theta}{arg\\,max} \\sum_{i=1}^{m} \\log{p_{model}({\\bf x}^{(i)}; \\theta)}$$\n",
    "- What is our choice of $p_{model}$? and how do we maximize it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Taxonomy of generative modeling</center></h3>\n",
    "\n",
    "<div style=\"width:fit-content;display:block;margin-right:auto;margin-left:auto;\">\n",
    "    <img style=\"display:block;margin:auto;\" src=\"images/taxonomy.png\" width=80% height=auto>\n",
    "</div>\n",
    "<p><center>Types of generative models (maximum likelihood)</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Properties of GANs compared to other models</center></h3>\n",
    "\n",
    "- GANs are implicit density models\n",
    "    - A black box: we don't have access to the actual distribution, we can only draw samples from it.\n",
    "- Explicit models define the distribution explicitly. We have a known representation of $p_{model}$.\n",
    "    - The difficulty comes in having an explicit model complex enough to capture the data complexity of $p_{data}$, while still being computationally tractable.\n",
    "        - Bound on complexity of model to ensure tractability\n",
    "    - e.g. Fully Visible Belief Networks (FVBNs), Variational Autoencoders\n",
    "- Advantages\n",
    "    - More computationally tractable than explicit models\n",
    "        - Does not use any Markov Chains\n",
    "        - Can be trained using back-propagation\n",
    "    - No approximations needed. Can learn any $p_{data}$ distribution (given enough examples)\n",
    "    - Subjectively, the research community has found that GANs provide better samples than any other method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Adversarial Training</center></h3>\n",
    "\n",
    "- There are two neural networks:\n",
    "    - Generator, $G$\n",
    "        - To learn the generator's distribution $p_{g}$ over the data ${\\bf x}$, define a prior $p_{\\bf z}({\\bf z})$ on input latent variables, ${\\bf z}$\n",
    "            - ${\\bf z}$ is usually chosen to be a uniform random variable\n",
    "        - We create a mapping from ${\\bf z} \\rightarrow {\\bf x}$ through the generator, $G({\\bf z};\\theta_{g})$\n",
    "            - Thus, we obtain \"fake\" samples from $G$, i.e. ${\\bf x} = G({\\bf z};\\theta_{g})$\n",
    "    - Discriminator, $D$\n",
    "        - The discriminator is trained on both the real data, and the data generated from the generator.\n",
    "        - The goal is to distinguish the real data from the generated fake data\n",
    "            - This is represented by $D({\\bf x};\\theta_{d})$, which is the probability that a sample ${\\bf x}$ comes from $p_{data}$ rather than $p_{g}$\n",
    "    - Train both networks with back-propagation/gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Adversarial Training (continued)</center></h3>\n",
    "\n",
    "- The two networks are trained in an adversarial manner\n",
    "    - The objective of the generator network is to fool the discriminator\n",
    "    - The objective of the discriminator is to distinguish fake samples from real samples\n",
    "- This adversarial training framework can be described as a two-player minimax game (with value function $V(G,D)$):\n",
    "\n",
    "    $$ \\underset{G}{\\min} \\underset{D}{\\max} V(D,G) = \\mathbb{E}_{{\\bf x} \\sim p_{data}({\\bf x})}[\\log{D({\\bf x})}] + \\mathbb{E}_{{\\bf z} \\sim p_{\\bf z}({\\bf z})}[\\log{1 - D(G({\\bf z}))}] $$\n",
    "\n",
    "- One can use game theory to analyze this framework, and can find that the Nash equilibrium of this game occurs when $p_{g} = p_{data}$ (more on this in a bit)\n",
    "- Note that in practice, most people tend to train G to maximize $\\log{D(G({\\bf z}))}$, instead of minimizing $\\log{1 - D(G({\\bf z}))}$ (provides stronger gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/training.png\" width=100% height=auto>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Adversarial Training (continued)</center></h3>\n",
    "\n",
    "- (a) Adversarial pair near convergence\n",
    "- (b) For any given $G$, $D$ converges to $\\frac{p_{data}({\\bf x})}{p_{data}({\\bf x}) + p_{g}({\\bf x})}$, the optimal discriminator\n",
    "- (c) After an update to $G$, gradient of $D$ guides $G$ to flow to regions classified as data\n",
    "- (d) If $G$ and $D$ have enough network capacity, $p_{g}$ converges to $p_{data}$ and the discriminator cannot tell the difference between the fake and real samples, i.e. $D({\\bf x}) = \\frac{1}{2}$ \n",
    "\n",
    "<div style=\"width:fit-content;display:block;margin-right:auto;margin-left:auto;\">\n",
    "    <img src=\"images/adversarial.png\" width=100% height=auto>\n",
    "</div>\n",
    "<p><center>(D, blue, dashed line), (G, green, solid line), (True data distribution, black, dotted line)</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Global Optimality of $p_{g} = p_{data}$</center></h3>\n",
    "\n",
    "- **Proposition 1.** For $G$ fixed, the optimal discriminator $D$ is:\n",
    "\n",
    "    $$D_{G}^{*}({\\bf x}) = \\frac{p_{data}({\\bf x})}{p_{data}({\\bf x}) + p_{g}({\\bf x})}$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;**Proof**:\n",
    "- For any fixed $G$, $D$ tries to maximize the quantity $V(G,D)$:\n",
    "\n",
    "    $$ V(D,G) = \\mathbb{E}_{{\\bf x} \\sim p_{data}({\\bf x})}[\\log{D({\\bf x})}] + \\mathbb{E}_{{\\bf z} \\sim p_{\\bf z}({\\bf z})}[\\log{1 - D(G({\\bf z}))}] $$\n",
    "\n",
    "- We can remove dependence on G, by replacing the expectation with respect to ${\\bf z}$ to one with respect to ${\\bf x}$, we get:\n",
    "\n",
    "    $$ V(D) = \\mathbb{E}_{{\\bf x} \\sim p_{data}({\\bf x})}[\\log{D({\\bf x})}] + \\mathbb{E}_{{\\bf x} \\sim p_{g}({\\bf x})}[\\log{1 - D({\\bf x})}] $$\n",
    "\n",
    "- Taking the derivative of this term and setting to 0 gives **Proposition 1** defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Global Optimality of $p_{g} = p_{data}$ (continued)</center></h3>\n",
    "\n",
    "- We can reformulate the minimax game as:\n",
    "\n",
    "$$ C(G) = \\mathbb{E}_{{\\bf x} \\sim p_{data}({\\bf x})}[\\log{\\frac{p_{data}({\\bf x})}{p_{data}({\\bf x}) + p_{g}({\\bf x})}}] + \\mathbb{E}_{{\\bf x} \\sim p_{g}({\\bf x})}[\\log{\\frac{p_{g}({\\bf x})}{p_{data}({\\bf x}) + p_{g}({\\bf x})}}] $$\n",
    "\n",
    "- **Theorem 1.** The global minimum of the virtual training criterion $C(G)$ is achieved if and only if $p_{g} = p_{data}$. At the point, $C(G)$ achieves the value $-\\log{4}$.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;**Proof:**\n",
    "- If we assume $p_{g} = p_{data}$, $D_{G}^{*}({\\bf x}) = \\frac{1}{2}$, and we get that $C(G) = -\\log 4$\n",
    "- (With some effort) we can see that this is the best minimum by rearranging $C(G)$:\n",
    "\n",
    "    $$ C(G) = -\\log{4} + KL\\left(p_{data} \\Big{\\|} \\frac{p_{data}+p_{g}}{2} \\right) + KL\\left(p_{g} \\Big{\\|} \\frac{p_{data}+p_{g}}{2} \\right)$$\n",
    "where $KL$ is the Kullback-Leibler divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Global Optimality of $p_{g} = p_{data}$ (continued)</center></h3>\n",
    "\n",
    "-  We recognize that the second half of the expression is twice the Jensen-Shannon divergence, which measures the similarity between two probability distribution:\n",
    "\n",
    "    $$ C(G) = -\\log{4} + 2\\cdot JSD(p_{data} \\| p_{g}) $$\n",
    "\n",
    "- By construction, the JS divergence, is always $\\geq 0$, and 0 when the two probability distributions are the same\n",
    "- It is then easy to see that $-\\log 4$ is the global minimum of $C(G)$ and that the only solution is $p_{g} = p_{data}$, i.e. the generator distribution is indistinguishable from the data distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Convergence of $p_{g} = p_{data}$</center></h3>\n",
    "\n",
    "- **Proposition 2.** If $G$ and $D$ have enough capacity, and at each step of Algorithm 1, the discriminator is allowed to reach its optimum given $G$, and $p_{g}$ is updated so as to improve the criterion\n",
    "\n",
    "    $$ \\mathbb{E}_{{\\bf x} \\sim p_{data}({\\bf x})}[\\log{D_{G}^{*}({\\bf x})}] + \\mathbb{E}_{{\\bf x} \\sim p_{g}({\\bf x})}[\\log{1 - D_{G}^{*}({\\bf x})}] $$\n",
    "then $p_{g}$ converges to $p_{data}$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;**Proof**:\n",
    "- Consider $V(G,D)$ = $U(p_{g},D)$. $U(p_{g},D)$ is convex in $p_{g}$.\n",
    "    - “The subderivatives of a supremum of convex functions include the derivative of the function at the point where the maximum is attained.” This [post](https://medium.com/@samramasinghe/generative-adversarial-networks-a-theoretical-walk-through-5889d5a8f2bb) may help understand this statement.\n",
    "- With sufficiently small updates of $p_{g}$, $p_{g}$ converges to $p_{x}$\n",
    "- In practice, we optimize the $\\theta_{g}$, the parameters of the network $G$, rather than $p_{g}$ itself\n",
    "    - Performance of neural networks still hold up well even without theoretical guarantees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Architecture and Results</center></h3>\n",
    "\n",
    "- GAN architecture\n",
    "    - Generator: Mixture of ReLU and Sigmoid Activations\n",
    "    - Discriminator: Maxout activations and Dropout\n",
    "    - Noise only applied as input to bottommost layer of generator network\n",
    "- Peformance compared with Deep Belief Networks, Stacked Autoencoders, and Generative Stochastic Networks\n",
    "    - Evaluation done via Parzen window-based log-likelihood estimates on generated samples (higher is better, increased likelihood that generated model fits)\n",
    "    - Cross-validation done to obtain $\\sigma$\n",
    "    - Goodfellow mentions that this method of evaluation has high variance, but best method to their knowledge (at the time)\n",
    "\n",
    "<div style=\"width:fit-content;display:block;margin-right:auto;margin-left:auto;\">\n",
    "    <img src=\"images/results.png\" width=100% height=auto>\n",
    "</div>\n",
    "<p><center>GAN Results on MNIST, Toronto Face Database, and CIFAR-10</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/results2.png\" width=100% height=auto>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/latentwalk.png\" width=100% height=auto>\n",
    "<p><center>Latent Space Walk</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Advantages/Disadvantages</center></h3>\n",
    "\n",
    "- Disadvantages\n",
    "    - An implicit representation of $p_{g}$\n",
    "    - $D$ must be synchronized well with $G$ during training\n",
    "        - G must not be trained too much without updating D, in order to avoid \"the Helvetica scenario\" a.k.a mode collapse\n",
    "        - G collapses too many values of ${\\bf z}$ to the same ${\\bf x}$ to have enough diversity to model $p_{data}$\n",
    "- Advantages\n",
    "    - No Markov Chains\n",
    "    - Back-propogation to get gradients\n",
    "    - No inferences needed during learning\n",
    "    - Adaptable model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Proposed Future Directions</center></h3>\n",
    "\n",
    "- Conditional Generative Models ([Conditional GANs](https://arxiv.org/abs/1411.1784))\n",
    "- Learned approximate inference ([Recovery of latent variables from GANs](https://arxiv.org/abs/1702.04782))\n",
    "- Semi-supervised Learning ([Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498))\n",
    "- Efficiency improvements (Too many to list here...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>References</center></h1>\n",
    "\n",
    "1. I. J. Goodfellow et al., “Generative Adversarial Networks,” arXiv:1406.2661 [cs, stat], Jun. 2014.\n",
    "2. I. Goodfellow, “NIPS 2016 Tutorial: Generative Adversarial Networks,” arXiv:1701.00160 [cs], Dec. 2016.\n",
    "3. https://srome.github.io/An-Annotated-Proof-of-Generative-Adversarial-Networks-with-Implementation-Notes/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
