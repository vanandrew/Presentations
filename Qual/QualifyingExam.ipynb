{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 class=\"text-center\">Generative Modeling of Neuroimaging Data using Generative\n",
    "Adversarial Networks</h1>\n",
    "<br>\n",
    "<h6 class=\"text-center\">Andrew Van</h6>\n",
    "<h6 class=\"text-center\">Advisor: Nico Dosenbach</h6>\n",
    "<script type=\"text/javascript\">\n",
    "$(window).load(function(){\n",
    "    Reveal.configure({\n",
    "        transition: 'fade' // none/fade/slide/convex/concave/zoom\n",
    "    })\n",
    "});    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       "   $('div.input').hide();\n",
       "   $('div.prompt.output_prompt').css('opacity', 0);\n",
       " } else {\n",
       "   $('div.input').show();\n",
       "   $('div.prompt.output_prompt').css('opacity', 1);\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$(document).ready(code_toggle);\n",
       "</script>\n",
       "<a href=\"javascript:code_toggle()\"><button>Toggle Code</button></a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    "   $('div.input').hide();\n",
    "   $('div.prompt.output_prompt').css('opacity', 0);\n",
    " } else {\n",
    "   $('div.input').show();\n",
    "   $('div.prompt.output_prompt').css('opacity', 1);\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$(document).ready(code_toggle);\n",
    "</script>\n",
    "<a href=\"javascript:code_toggle()\"><button>Toggle Code</button></a>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Overview</h3>\n",
    "\n",
    "- What are GANs?\n",
    "    - Theory\n",
    "    - Limitations\n",
    "- Model Training\n",
    "    - Progressive GAN and Wasserstein Distance (How do these address limitations?)\n",
    "    - Results\n",
    "- Applications\n",
    "    - Reconstruction in Underdetermined Systems\n",
    "    - Anomaly Detection\n",
    "- Future Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">What are Generative Adversarial Networks (GANs)?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">What are GANs?</h3>\n",
    "\n",
    "- Take two networks and train them in an adversarial manner...\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/GANdiag.png\" width=60% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\">GAN Training Process</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">What are GANs?</h3>\n",
    "\n",
    "- ...and they can make really convincing fake images.\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/stylegan-teaser.png\" width=90% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\">These are not real people! <a href=\"https://arxiv.org/abs/1812.04948\" target=\"_blank\">StyleGAN</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Fake Images? So What?</h3>\n",
    "\n",
    "- GANs capture an underlying process that generated our dataset.\n",
    "    - Creating realistic fake examples is the byproduct of a well-trained model.\n",
    "- A data-driven prior!\n",
    "        \n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/imageinpainting.png\" width=75% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\"><a href=\"https://arxiv.org/abs/1604.07379\" target=\"_blank\">Image Inpainting</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">What is Generative Modeling?</h3>\n",
    "\n",
    "- Discriminative models\n",
    "    - Map high-dimensional data to a class label\n",
    "    - e.g. Given an image, is it a cat/dog?\n",
    "- Generative models answer a somewhat opposite question\n",
    "    - Given a sample drawn from a distribution, we want to learn an estimate of that distribution\n",
    "    - e.g. Given a set of cats/dogs, learn the images that generate each class.\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/density_estimation.png\" width=75% height=auto>\n",
    "</div>\n",
    "<p><center>Generative Modeling: Estimating a distribution from sample</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center>Taxonomy of generative modeling</center></h3>\n",
    "\n",
    "<div>\n",
    "    <img style=\"display:block;margin:auto;\" src=\"images/taxonomy.png\" width=80% height=auto>\n",
    "</div>\n",
    "<p><center>Types of generative models (maximum likelihood)</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">GANs compared to other generative models</h3>\n",
    "\n",
    "- GANs are implicit density models\n",
    "    - A black box: we don't have access to the actual distribution, we can only draw samples from it.\n",
    "- Explicit models define the distribution explicitly. We have a known parameterization of our model.\n",
    "    - The difficulty comes in having an explicit model complex enough to capture the data complexity of dataset, while still being computationally tractable.\n",
    "        - Bound on complexity of model to ensure tractability\n",
    "    - e.g. Fully Visible Belief Networks (FVBNs), Variational Autoencoders\n",
    "- Advantages\n",
    "    - More computationally tractable than explicit models\n",
    "        - Does not use any Markov Chains\n",
    "        - Can be trained using back-propagation\n",
    "    - No approximations needed. Can learn any dataset distribution (given enough examples and layers).\n",
    "    - Subjectively, the research community has found that GANs provide better samples than any other method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">GAN Theory</h3>\n",
    "\n",
    "- Two networks: generator and discriminator setup in a zero-sum game\n",
    "    - Discriminator Objective: Pick out fake from real\n",
    "    - Generator Objective: Create a fake indistinguishable from real\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/GANdiag.png\" width=60% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\">GAN Training Process</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">GAN Theory</h3>\n",
    "\n",
    "- This is a two-player minimax game:\n",
    "\n",
    "$$ \\min_{G} \\max_{D} \\underset{\\mathbf{x} \\sim \\mathbb{P}_{r}}{\\mathbb{E}}[\\log D(\\mathbf{x})] + \\underset{\\mathbf{z} \\sim \\mathbb{P}_{\\mathbf{z}}}{\\mathbb{E}}[\\log (1 - D(G(\\mathbf{z})))] $$\n",
    "\n",
    "- From game theory, we find the Nash Equilibirum for this system\n",
    "    - We reach Nash Equilibrium when $\\mathbb{P}_{r} = \\mathbb{P}_{g}$, and $D(x) = 0.5$ for all inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Limitations</h3>\n",
    "\n",
    "- Difficult to acheive Nash Equilibirum\n",
    "- Low Support\n",
    "- Vanishing Gradients\n",
    "- Mode Collapse\n",
    "- Lack of Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Difficult to acheive Nash Equilibirum</h3>\n",
    "\n",
    "- Minimax optimization may not converge stably\n",
    "- Example: Minimaxing f(x,y) = xy\n",
    "    - Signs of x,y are opposite --> oscillations\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/nash_equilibrium.png\" width=80% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\">Instability of objective functions</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Low Support</h3>\n",
    "\n",
    "- When two distributions lie in a low dimensional manifold, they are (with very high probability) disjoint\n",
    "    - A perfect discriminator exists that can separate both exactly\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/low_dim_manifold.png\" width=80% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\">Distributions of both networks lie in a lower dimensional space</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Vanishing Gradients</h3>\n",
    "\n",
    "- Low support can lead to the discriminator improving too fast\n",
    "    - If the discriminator is perfect too early, generator doesn't have any gradients to backprop on\n",
    "- So slow discriminator learning?\n",
    "    - If the discriminator is bad, generator doesn't learn accurately\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/GAN_vanishing_gradient.png\" width=60% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\">Vanishing Gradients</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Mode Collapse</h3>\n",
    "\n",
    "- GAN collapse the value of several inputs to the same output\n",
    "- Why does it happen?\n",
    "    - Max-Min instead of Min-Max?\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/mode_collapse.png\" width=100% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\">Helvetica Scenario</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Lack of Evaluation Metric</h3>\n",
    "\n",
    "- Unclear how to universally evaluate GANs quantitatively at present\n",
    "- Popular measure in many GAN papers is Frechet Inception Distance or Inception Score\n",
    "    - Only works for natural image scenes, unsuitable for medical imaging applications\n",
    "- [Boraj 2018](https://arxiv.org/abs/1802.03446) gives comprehensive review of proposed evaluation method (will touch on this again)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Model Training</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Dataset Characterization</h3>\n",
    "\n",
    "- Human Connectome Project (HCP) 1200 Young Adult Dataset\n",
    "- 1113 T1s, 1783 Unique Volumes\n",
    "    - 1707 Unique Volumes after QC applied (issue code A)\n",
    "- 256 x 256 x 320, 0.7 mm voxel\n",
    "- Volumes unstacked in axial direction\n",
    "    - 256 slices of 256 x 320, zero-padded to 512 x 512\n",
    "- Total dataset size: 546,240 TI slices of 512 x 512 resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Progressive GAN</h3>\n",
    "\n",
    "- Grows the architecture of the network during training\n",
    "    - Stablilizes training, since network has to learn less features first\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/progarch.png\" width=70% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\">Progressive GAN Architecture</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Progressive GAN</h3>\n",
    "\n",
    "- Transition to next resolution no occurs smoothly\n",
    "    - During transition, acts a residual block passing in lower resolution image to the output\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/proggrow.png\" width=70% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\">Growth Block</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Wasserstein Distance</h3>\n",
    "\n",
    "- Instead of the original GAN loss function, we use Wasserstein Distance\n",
    "    - Wasserstein distance attempts to solve the problem of low support and vanishing gradients\n",
    "        - Also solves mode collapse? \n",
    "    - Replaces the Discriminator with a Critic; Gives a measure of how different the fake samples are from the real (contrast with original discriminator which does a binary choice)\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/WD.png\" width=50% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\">Wasserstein Distance</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Wasserstein Distance with Gradient Penalty</h3>\n",
    "\n",
    "- Wasserstein Distance has 1-Lipshitz constraint (which was actually shown to be gradient norm = 1)\n",
    "    - Gradient of critic must be equal to 1 everywhere\n",
    "    - We add gradient penalty term to satisfy this constraint\n",
    "\n",
    "$$ \\min_{G} \\max_{D} \\underset{\\mathbf{z} \\sim \\mathbb{P}_{\\mathbf{z}}}{\\mathbb{E}}[D(G(\\mathbf{z}))] - \\underset{\\mathbf{x} \\sim \\mathbb{P}_{r}}{\\mathbb{E}}[D(\\mathbf{x})] + \\lambda \\underset{\\hat{\\mathbf{x}} \\sim \\mathbb{P}_{\\hat{\\mathbf{x}}}}{\\mathbb{E}}[(\\lVert \\nabla_{\\hat{\\mathbf{x}}} D(\\hat{\\mathbf{x}}) \\rVert_{2} - 1)^{2}] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Training Parameters</h3>\n",
    "\n",
    "- Trained with TensorFlow on NVIDIA Tesla V100 GPU on AWS/NVIDIA Geforce RTX 2080 Ti locally\n",
    "- Adam Optimizer with initial learning rate set to 1e-3 for each resolution layer\n",
    "- Resolution doubling occured every 1.2 million images (600k transition, 600k iterations @ resolution)\n",
    "- Mini-batch sizes: 4 × 4: 128, 8 × 8: 128, 16 × 16: 128, 32 × 32: 64, 64 × 64: 32, 128 × 128: 16, 256 × 256: 8, and 512 × 512: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Results</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Training Process</h3>\n",
    "<br>\n",
    "<video style=\"display:block;margin-right:auto;margin-left:auto;\" width=90% height=auto controls loop>\n",
    "    <source src=\"videos/train.webm\" type=\"video/webm\">\n",
    "</video>\n",
    "<p style=\"text-align: center\">Snapshots throughout training</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Loss Functions</h3>\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/loss.png\" width=50% height=auto>\n",
    "</div>\n",
    "<p style=\"text-align: center\">Wasserstein Distance</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Fake vs. Real</h3>\n",
    "<br>\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/real.png\" width=90% height=auto>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p style=\"text-align: center\">Real Images</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Fake vs. Real</h3>\n",
    "<br>\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/fake.png\" width=90% height=auto>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p style=\"text-align: center\">Fake Images</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Latent Vector Walk</h3>\n",
    "<br>\n",
    "<video style=\"display:block;margin-right:auto;margin-left:auto;\" width=60% height=auto controls loop>\n",
    "    <source src=\"videos/interp.webm\" type=\"video/webm\">\n",
    "</video>\n",
    "<p style=\"text-align: center\">Snapshots throughout training</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Nearest Neighbor</h3>\n",
    "\n",
    "- Output closest matching image in training set\n",
    "\n",
    "<div>\n",
    "<img style=\"margin-right:0;margin-left:0;margin-top:0;float:left\" src=\"images/fakeimg.png\" width=45% height=auto>\n",
    "<img style=\"margin-right:0;margin-left:0;margin-top:0;float:right\" src=\"images/realimg.png\" width=45% height=auto>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p style=\"text-align: center\">(left) random output from generator (right) nearest neighbor to fake image in training set</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">How to evaluate GANs?</h3>\n",
    "\n",
    "- What to use?\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/evaltable.png\" width=75% height=auto>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Task-Based Assessments of Image Quality (TAIQ)</h3>\n",
    "\n",
    "- Evaluation of GANs based on their performance on a task\n",
    "    - This would be an evaluation of a system that a GAN is one component of\n",
    "    - e.g. Looking at reconstruction accuracy when using a GAN based reconstruction algorithm using various trained GAN models\n",
    "    - e.g. Doing an ROC analysis on a GAN based anomaly detector\n",
    "- TAIQ gives relevant metrics on the model with tasks that we care about\n",
    "    - Downside: Does not tell you how a GAN model fails, may still need other independent metrics for mode collapse, sample fidelity, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Applications</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Underdetermined Reconstruction</h3>\n",
    "\n",
    "- In image reconstruction, we are interested in the following problem:\n",
    "\n",
    "$$y = Ax + \\eta$$\n",
    "\n",
    "where $x \\in \\mathbb{R}^{n}$ is the object to reconstruct, $y \\in \\mathbb{R}^{m}$ describes the measurements, $A \\in \\mathbb{R}^{m \\times n}$ is the system operator/measurement matrix, and $\\eta$ is additive noise. The goal is to recover the object, $x$, using measurements from our system, $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Underdetermined Reconstruction with Sparsity</h3>\n",
    "\n",
    "- In reconstruction applications like Super-Resolution or Compressed Sensing, the system is underdetermined.\n",
    "    - The $rank(A) < n$.\n",
    "- In order to guarantee unique recovery, further assumptions about the data must be used.\n",
    "    - One possible solution: sparsity (commonly used in compressed sensing)\n",
    "    - Unique recovery of an underdetermined system using sparsity assumptions through $\\ell_{1}$-regularization.\n",
    "   \n",
    "$$ \\min_{x} \\lVert x \\rVert_{1}\\\\ s.t.\\ Ax = y \\nonumber $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Underdetermined Reconstruction with GANs</h3>\n",
    "\n",
    "- A stronger prior: reconstructions that lie in the range of a well-trained generator.\n",
    "    \n",
    "$$ Find\\ \\hat{\\mathbf{x}} = G(\\hat{\\mathbf{z}}) \\\\ s.t.\\ \\hat{\\mathbf{z}} = \\arg \\min_{\\mathbf{z}} \\lVert AG(\\mathbf{z}) - y \\rVert_{2}^{2}$$\n",
    "\n",
    "<div>\n",
    "<img style=\"display:block;margin-right:auto;margin-left:auto;\" src=\"images/lassogen.png\" width=60% height=auto>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Anomaly Detection</h3>\n",
    "\n",
    "- Anomaly: a sample that is different from the rest of the dataset\n",
    "    - We are interested in anomaly detection for Quality Control\n",
    "- Deep learning methods like GANs can capture high dimensional datasets\n",
    "    - Potential improvement in anomaly detection performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">AnoGAN</h3>\n",
    "\n",
    "- Finding anomalies through residual and discrimination loss\n",
    "\n",
    "$$ L(\\mathbf{x}) = \\min_{\\mathbf{z}} \\lVert \\mathbf{x} - G(\\mathbf{z}) \\rVert_{2}^{2} + \\lVert \\mathbf{f}(\\mathbf{x}) - \\mathbf{f}(G(\\mathbf{z})) \\rVert_{2}^{2}$$\n",
    "\n",
    "- Residual loss: How similar a new example from the most similar (L2) sample from the generator\n",
    "- Discrimination loss: How similar the new example is to the most similar sample from the generator in terms of discriminator features (feature matching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Future Directions</h3>\n",
    "\n",
    "- Examine the efficacy of each evaluation method proposed in [Borji 2018](https://arxiv.org/abs/1802.03446) on our own data\n",
    "- Try newer, better GAN architectures such as [StyleGAN](https://arxiv.org/abs/1812.04948)\n",
    "- Explore generalization of GANs with training/test splits\n",
    "- Investigate and define a reconstruction problem to apply GAN-based reconstruction techniques\n",
    "- Explore effectiveness of GAN anomaly detection frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 class=\"text-center\">Acknowledgements</h3>\n",
    "\n",
    "- Mark Anastasio, PhD\n",
    "- Sayantan Bhadra\n",
    "- Abhinav Jha, PhD    \n",
    "- Nico Dosenbach, MD/PhD    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
